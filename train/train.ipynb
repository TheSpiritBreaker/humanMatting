{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution() # faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "class DataGen(Sequence):\n",
    "    def __init__(self, x, y, batch_size):\n",
    "        self.x, self.y = x, y\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_batch = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        y_batch = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        # 1:1, 4:3, 16:9, 2:1\n",
    "        shapes = [(512, 384), (384, 512), (512, 288), (288, 512), (512, 256), (256, 512), (256, 256), (256, 256)]\n",
    "        shape = shapes[np.random.choice(len(shapes))]\n",
    "        # shape = (256, 256)\n",
    "        \n",
    "        x_ret, y_ret = [], []\n",
    "        for x_file_name, y_file_name in zip(x_batch, y_batch):\n",
    "            x_img = cv2.resize(cv2.imread(x_file_name, 0), shape)\n",
    "            y_img = cv2.resize(cv2.imread(y_file_name, cv2.IMREAD_UNCHANGED), shape)\n",
    "            probs = y_img[:,:,3] / 255.0\n",
    "            alpha_map = np.zeros((*probs.shape, 2))\n",
    "            alpha_map[:,:,0] = 1 - probs\n",
    "            alpha_map[:,:,1] = probs\n",
    "            x_ret.append(x_img[:,:,np.newaxis])\n",
    "            y_ret.append(alpha_map)\n",
    "\n",
    "        return np.array(x_ret), np.array(y_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, ReLU, Conv2D, MaxPooling2D, \\\n",
    "                                    Conv2DTranspose, UpSampling2D, \\\n",
    "                                    Add, Concatenate, BatchNormalization\n",
    "def LikeUnet():\n",
    "    # input\n",
    "    im = Input(shape=(None, None, 1))\n",
    "    pre = Conv2D(8, 3, padding='same', activation='relu')(im)\n",
    "    # conv1\n",
    "    a = Conv2D(16, 3, padding='same', name='conv1-1')(pre)\n",
    "    b = Conv2D(16, (1, 3), padding='same', name='conv1-2')(pre)\n",
    "    c = Conv2D(16, (3, 1), padding='same', name='conv1-3')(pre)\n",
    "    x = Add()([a, b, c])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    conv1 = MaxPooling2D(2)(x)\n",
    "    # conv2\n",
    "    a = Conv2D(32, 3, padding='same', name='conv2-1')(conv1)\n",
    "    b = Conv2D(32, (1, 3), padding='same', name='conv2-2')(conv1)\n",
    "    c = Conv2D(32, (3, 1), padding='same', name='conv2-3')(conv1)\n",
    "    x = Add()([a, b, c])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    conv2 = MaxPooling2D(2)(x)\n",
    "    # conv3\n",
    "    a = Conv2D(32, 3, padding='same', name='conv3-1')(conv2)\n",
    "    b = Conv2D(32, (1, 3), padding='same', name='conv3-2')(conv2)\n",
    "    c = Conv2D(32, (3, 1), padding='same', name='conv3-3')(conv2)\n",
    "    x = Add()([a, b, c])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    conv3 = MaxPooling2D(2)(x)\n",
    "    # conv4\n",
    "    a = Conv2D(32, 3, padding='same', name='conv4-1')(conv3)\n",
    "    b = Conv2D(32, (1, 3), padding='same', name='conv4-2')(conv3)\n",
    "    c = Conv2D(32, (3, 1), padding='same', name='conv4-3')(conv3)\n",
    "    x = Add()([a, b, c])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    conv4 = MaxPooling2D(2)(x)\n",
    "    # conv5\n",
    "    a = Conv2D(64, 3, padding='same', name='conv5-1')(conv4)\n",
    "    b = Conv2D(64, (1, 3), padding='same', name='conv5-2')(conv4)\n",
    "    c = Conv2D(64, (3, 1), padding='same', name='conv5-3')(conv4)\n",
    "    x = Add()([a, b, c])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    conv5 = MaxPooling2D(2)(x)\n",
    "    # transconv1\n",
    "    a = Conv2D(64, 3, padding='same', name='conv6-1')(conv5)\n",
    "    b = Conv2D(64, (1, 3), padding='same', name='conv6-2')(conv5)\n",
    "    c = Conv2D(64, (3, 1), padding='same', name='conv6-3')(conv5)\n",
    "    x = Add()([a, b, c])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2DTranspose(64, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = UpSampling2D(2, interpolation='bilinear')(x)\n",
    "    # transconv2\n",
    "    x = Concatenate()([conv4, x])\n",
    "    a = Conv2D(32, 3, padding='same', name='conv7-1')(x)\n",
    "    b = Conv2D(32, (1, 3), padding='same', name='conv7-2')(x)\n",
    "    c = Conv2D(32, (3, 1), padding='same', name='conv7-3')(x)\n",
    "    x = Add()([a, b, c])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2DTranspose(32, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = UpSampling2D(2, interpolation='bilinear')(x)\n",
    "    # transconv3\n",
    "    x = Concatenate()([conv3, x])\n",
    "    a = Conv2D(32, 3, padding='same', name='conv8-1')(x)\n",
    "    b = Conv2D(32, (1, 3), padding='same', name='conv8-2')(x)\n",
    "    c = Conv2D(32, (3, 1), padding='same', name='conv8-3')(x)\n",
    "    x = Add()([a, b, c])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2DTranspose(32, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = UpSampling2D(2, interpolation='bilinear')(x)\n",
    "    # transconv4\n",
    "    x = Concatenate()([conv2, x])\n",
    "    a = Conv2D(32, 3, padding='same', name='conv9-1')(x)\n",
    "    b = Conv2D(32, (1, 3), padding='same', name='conv9-2')(x)\n",
    "    c = Conv2D(32, (3, 1), padding='same', name='conv9-3')(x)\n",
    "    x = Add()([a, b, c])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2DTranspose(32, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = UpSampling2D(2, interpolation='bilinear')(x)\n",
    "    # transconv5\n",
    "    x = Concatenate()([conv1, x])\n",
    "    a = Conv2D(16, 3, padding='same', name='conv10-1')(x)\n",
    "    b = Conv2D(16, (1, 3), padding='same', name='conv10-2')(x)\n",
    "    c = Conv2D(16, (3, 1), padding='same', name='conv10-3')(x)\n",
    "    x = Add()([a, b, c])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2DTranspose(16, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = UpSampling2D(2, interpolation='bilinear')(x)\n",
    "    # output\n",
    "    x = Conv2D(8, 3, padding='same', activation='relu')(x)\n",
    "    out = Conv2D(2, 1, padding='same', activation='softmax')(x)\n",
    "    return Model(inputs=im, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"x_train.txt\", \"r\") as f:\n",
    "    x_train = [filename[:-1] for filename in f.readlines()]\n",
    "with open(\"y_train.txt\", \"r\") as f:\n",
    "    y_train = [filename[:-1] for filename in f.readlines()]\n",
    "with open(\"x_val.txt\", \"r\") as f:\n",
    "    x_val = [filename[:-1] for filename in f.readlines()]\n",
    "with open(\"y_val.txt\", \"r\") as f:\n",
    "    y_val = [filename[:-1] for filename in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGen = DataGen(x_train, y_train, batch_size=60)\n",
    "valGen = DataGen(x_val, y_val, batch_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import MeanIoU\n",
    "class mIoU(MeanIoU):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__(num_classes=num_classes, name=\"mIoU\")\n",
    "    \n",
    "    def __call__(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.argmax(y_true, axis=-1)\n",
    "        y_pred = tf.argmax(y_pred, axis=-1)\n",
    "        return super().__call__(y_true, y_pred, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model, model_from_json\n",
    "model = LikeUnet()\n",
    "with open('dark-pre.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "# with open('dark-micro.json', 'r') as f:\n",
    "#     json_string = f.read()\n",
    "# model = model_from_json(json_string)\n",
    "# model.load_weights('models\\\\dark-20-0.9766.h5')\n",
    "model.compile(optimizer=Adam(amsgrad=True),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[mIoU(num_classes=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "logdir = \"logs\\\\dark-pre\\\\\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir, profile_batch=0)\n",
    "filepath = \"models\\\\dark-pre-{epoch:02d}-{val_mIoU:.4f}.h5\"\n",
    "checkpoint_callback = ModelCheckpoint(filepath, monitor='val_mIoU', save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small dataset for debugging\n",
    "# model.fit_generator(generator=valGen, epochs=10, workers=8, shuffle=True)\n",
    "# model.save_weights('test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator=trainGen, validation_data=valGen, epochs=20, workers=8, shuffle=True,\n",
    "                    callbacks=[tensorboard_callback, checkpoint_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
